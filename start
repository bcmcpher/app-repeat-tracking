#!/bin/bash

## file inputs
ANAT=`jq -r '.anat' config.json`

## CSD fits
LMAX2=`jq -r '.lmax2' config.json`
LMAX4=`jq -r '.lmax4' config.json`
LMAX6=`jq -r '.lmax6' config.json`
LMAX8=`jq -r '.lmax8' config.json`
LMAX10=`jq -r '.lmax10' config.json`
LMAX12=`jq -r '.lmax12' config.json`
LMAX14=`jq -r '.lmax14' config.json`

TFILE=$ANAT

if [ -f $LMAX2 ]; then
    #echo "Transferring lmax2..."
    TFILE=$TFILE,$LMAX2
fi

if [ -f $LMAX4 ]; then
    #echo "Transferring lmax4..."
    TFILE=$TFILE,$LMAX4
fi

if [ -f $LMAX6 ]; then
    #echo "Transferring lmax6..."
    TFILE=$TFILE,$LMAX6
fi

if [ -f $LMAX8 ]; then
    #echo "Transferring lmax8..."
    TFILE=$TFILE,$LMAX8
fi

if [ -f $LMAX10 ]; then
    #echo "Transferring lmax10..."
    TFILE=$TFILE,$LMAX10
fi

if [ -f $LMAX12 ]; then
    #echo "Transferring lmax12..."
    TFILE=$TFILE,$LMAX12
fi

if [ -f $LMAX14 ]; then
    #echo "Transferring lmax14..."
    TFILE=$TFILE,$LMAX14
fi

NFIB=`jq -r '.num_fibers' config.json`

## use what exists to build file list

cat > part1.submit << EOF
universe = vanilla
executable = submit_jobs.sh

Requirements = HAS_SINGULARITY == TRUE

+ProjectName="Diffusion-predictor"
+SingularityImage = "/cvmfs/singularity.opensciencegrid.org/brainlife/mrtrix3:3.0_RC3"
+SingularityBindCVMFS = True

should_transfer_files = IF_NEEDED
when_to_transfer_output = ON_EXIT

# Send the job to Held state on failure.
on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)

# Periodically retry the jobs every 10 minutes, up to a maximum of 5 retries.
periodic_release =  (NumJobStarts < 5) && ((CurrentTime - EnteredCurrentStatus) > 600)

# remove job if it fails 5 times.
periodic_remove = (NumJobStarts == 5)

transfer_input_files = $TFILE
transfer_output_files = intermediate
# rep02,rep03,rep04,rep05,rep06,rep07,rep08,rep09,rep10

stream_output = True
output = part1.stdout.log
error = part1.stderr.log
log = part1.condor.out

queue
EOF

cat > part2.submit << EOF
universe = vanilla
executable = queue_jobs.sh

Requirements = HAS_SINGULARITY == TRUE

+ProjectName="Diffusion-predictor"
+SingularityImage = "/cvmfs/singularity.opensciencegrid.org/brainlife/mrtrix3:3.0_RC3"
+SingularityBindCVMFS = True

should_transfer_files = IF_NEEDED
when_to_transfer_output = ON_EXIT

# Send the job to Held state on failure.
on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)

# Periodically retry the jobs every 10 minutes, up to a maximum of 5 retries.
periodic_release =  (NumJobStarts < 5) && ((CurrentTime - EnteredCurrentStatus) > 600)

# remove job if it fails 5 times.
periodic_remove = (NumJobStarts == 5)

transfer_input_files = intermediate

stream_output = True
output = part2.stdout.\$(Process).log
error = part2.stderr.\$(Process).log
log = part2.condor.out

transfer_output_files = rep02
arguments = $NFIB 02
queue

transfer_output_files = rep03
arguments = $NFIB 03
queue

transfer_output_files = rep04
arguments = $NFIB 04
queue

transfer_output_files = rep05
arguments = $NFIB 05
queue

EOF

cat > submit.dag << EOF
JOB  PART1  part1.submit
JOB  PART2  part2.submit
PARENT PART1 CHILD PART2
EOF

condor_submit_dag submit.dag | grep "submitted to cluster" | cut -d " " -f 6 > jobid
#condor_submit_dag -terse submit.dag | cut -f 1 -d " " > jobid

