#!/bin/bash

# ## file inputs
# ANAT=./t1.nii.gz # `jq -r '.anat' config.json`

# ## CSD fits
# LMAX2=./lmax2.nii.gz # `jq -r '.lmax2' config.json`
# LMAX4=./lmax4.nii.gz # `jq -r '.lmax4' config.json`
# LMAX6=./lmax6.nii.gz # `jq -r '.lmax6' config.json`
# LMAX8=./lmax8.nii.gz # `jq -r '.lmax8' config.json`
# LMAX10=./lmax10.nii.gz # `jq -r '.lmax10' config.json`
# LMAX12=./lmax12.nii.gz # `jq -r '.lmax12' config.json`
# LMAX14=./lmax14.nii.gz # `jq -r '.lmax14' config.json`

NFIB=`jq -r '.num_fibers' config.json`

## use what exists to build file list

cat << EOF
universe = vanilla
arguments = $NFIB
executable = mrtrix3_tracking.sh

Requirements = HAS_SINGULARITY == TRUE

+ProjectName="Diffusion-predictor"
+SingularityImage = "/cvmfs/singularity.opensciencegrid.org/brainlife/mrtrix3:3.0_RC3"
+SingularityBindCVMFS = True

should_transfer_files = IF_NEEDED
when_to_transfer_output = ON_EXIT

# Send the job to Held state on failure.
on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)

# Periodically retry the jobs every 10 minutes, up to a maximum of 5 retries.
periodic_release =  (NumJobStarts < 5) && ((CurrentTime - EnteredCurrentStatus) > 600)

# remove job if it fails 5 times.
periodic_remove = (NumJobStarts == 5)

transfer_input_files = `jq -r '.anat' config.json`,`jq -r '.lmax2' config.json`,`jq -r '.lmax4' config.json`,`jq -r '.lmax6' config.json`
transfer_output_files = out

stream_output = True
output = stdout.log
error = stderr.log
log = condor.out

queue
EOF

